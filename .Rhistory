return(weight)
}
#-------------  MAIN PROGRAM ------------------
n <- 100 #dark matter
m <- 500 #visible matter
niter <- 200
fixed_x <- 0; fixed_y <- 0
for(k in 1:n) {
fixed_x[k] <- 2 * runif(1) - 0.5
fixed_y[k] <- 2 * runif(1) - 0.5
}
init_x <- 0; init_y <- 0
moving_x <- 0;  moving_y <- 0
rebirth <- 0; d2init <- 0;  d2last <- 0
for(k in 1:m) {
init_x[k] <- runif(1)
init_y[k] <- runif(1)
moving_x[k] <- init_x[k]
moving_y[k] <- init_y[k]
rebirth[k] <-0
d2init[k] <-0
d2last[k] <-0
}
tmp_x <- 0 ; tmp_y <- 0
delta <- 0
to_R <- 0
for(iteration in 1:niter) {
for(k in 1:m) {
x <- moving_x[k]
y <- moving_y[k]
new_x <- 0
new_y <- 0
sum_weight <- 0
for(l in 1:m) {
p <- moving_x[l]
q <- moving_y[l]
weight <- distance(x,y,p,q)
if(k==l) {weight <- 0}
new_x <- new_x + weight * p
new_y <- new_y + weight * q
sum_weight <- sum_weight + weight
}
for(l in 1:n) {
p <- fixed_x[l]
q <- fixed_y[l]
weight <- distance(x,y,p,q)
new_x <- new_x + weight * p
new_y <- new_y + weight * q
sum_weight <- sum_weight + weight
}
new_x <- new_x / sum_weight
new_y <- new_y / sum_weight
new_x <- new_x + 0.10 * (runif(1)-0.50)
new_y <- new_y + 0.10 * (runif(1)-0.50)
tmp_x[k] <- new_x
tmp_y[k] <- new_y
if(runif(1) < 0.1/(1+iteration)) {
tmp_x[k] <- runif(1)
tmp_y[k] <- runif(1)
rebirth[k] <- 1
}
}
delta[iteration] <- 0
for(k in 1:m) {
delta[iteration] <- delta[iteration] + abs(moving_x[k]-tmp_x[k]) +
abs(moving_y[k]-tmp_y[k])
d2init[k] <- abs(moving_x[k] - init_x[k]) + abs(moving_y[k] - init_y[k])
d2last[k] <- abs(moving_x[k] - tmp_x[k]) + abs(moving_y[k] - tmp_y[k])
moving_x[k] <- tmp_x[k]
moving_y[k] <- tmp_y[k]
}
delta[iteration] <- delta[iteration]/m
iter_val <- rep(iteration,m)
to_R_tmp <- cbind(iter_val, moving_x, moving_y, rebirth, d2init, d2last)
to_R <- rbind(to_R, to_R_tmp)
} #for(iteration...
version
install.packages(c("foreign", "nlme"))
# Get StackOverflow data
# Get StackOverflow data
get.stack<-function(tok) {
# Must check for XML install, thanks onertipaday!
if (!require(XML)) install.packages('XML')
library(XML)
# Enter a SO tag as character string, and number of tags are returned
#gsub is a grep-like command
#gsub(pattern, replacement, x, ignore.case = FALSE, perl = FALSE,
#     fixed = FALSE, useBytes = FALSE)
tok<-gsub("(/| )","-",tok)
tok<-gsub("#","%23",tok,fixed=TRUE)
base.stack<-"http://stackoverflow.com/questions/tagged/"
stack.tree<-htmlTreeParse(paste(base.stack,tok,sep=""),useInternalNodes=TRUE)
tag.count<-getNodeSet(stack.tree,"//div[@class='module']/div[@class='summarycount al']")
tag.num<-suppressWarnings(as.numeric(gsub(",","",xmlValue(tag.count[[1]]),fixed=TRUE)))
if(is.na(tag.num)) {
warning(paste("Something went wrong trying to parse '",tok,"'.\nNA returned",sep=""))
}
return(tag.num)
}
get.stack("references")
#get.stack("clojure")
#get.stack("hadoop")
#get.stack("r")
# Get StackOverflow data
get.stack<-function(tok) {
# Must check for XML install, thanks onertipaday!
if (!require(XML)) install.packages('XML')
library(XML)
# Enter a SO tag as character string, and number of tags are returned
#gsub is a grep-like command
#gsub(pattern, replacement, x, ignore.case = FALSE, perl = FALSE,
#     fixed = FALSE, useBytes = FALSE)
tok<-gsub("(/| )","-",tok)
tok<-gsub("#","%23",tok,fixed=TRUE)
base.stack<-"http://stackoverflow.com/questions/tagged/"
stack.tree<-htmlTreeParse(paste(base.stack,tok,sep=""),useInternalNodes=TRUE)
tag.count<-getNodeSet(stack.tree,"//div[@class='module']/div[@class='summarycount al']")
tag.num<-suppressWarnings(as.numeric(gsub(",","",xmlValue(tag.count[[1]]),fixed=TRUE)))
if(is.na(tag.num)) {
warning(paste("Something went wrong trying to parse '",tok,"'.\nNA returned",sep=""))
}
return(tag.num)
}
get.stack("references")
#get.stack("clojure")
#get.stack("hadoop")
#get.stack("r")
installed.packages()
devtools::install_github("nicolewhite/RNeo4j")
library(RNeo4j)
library(RNeo4j)
graph = startGraph("http://localhost:7474/db/data/")
source('~/scripts/rneo4.r')
source('~/scripts/rneo4.r')
source('~/scripts/rneo4.r')
View(stock)
source('~/scripts/rneo4.r')
source('~/scripts/rneo4.r')
MATCH (a)-[r]-(b)-[r2]-(c) RETURN a,b,c LIMIT 30
source('~/scripts/rneo4.r')
source('~/scripts/rneo4.r')
source('~/scripts/rneo4.r')
source('~/scripts/rneo4.r')
devtools::install_github("dataknowledge/visNetwork")
source('~/scripts/rneo4.r')
nodes
source('~/scripts/rneo4.r')
nodes
source('~/scripts/rneo4.r')
nodes
source('~/scripts/rneo4.r')
source('~/scripts/rneo4.r')
source('~/scripts/rneo4.r')
source('~/scripts/rneo4.r')
nodes
source('~/scripts/rneo4.r')
source('~/scripts/rneo4.r')
MATCH (a1:Person)-[:MATCHPROB]->(a2:Person)
source('~/scripts/rneo4.r')
source('~/scripts/rneo4.r')
nodes
source('~/scripts/rneo4.r')
edges
source('~/scripts/rneo4.r')
nodes
source('~/scripts/rneo4.r')
edges
source('~/scripts/rneo4.r')
source('~/scripts/rneo4.r')
source('~/scripts/rneo4.r')
library(igraph)
library(RNeo4j)
library(visNetwork)
library(jsonlite)
neo4j = startGraph("http://localhost:7474/db/data/")
summary(neo4j)
source('~/scripts/rneo4.r')
N <- 5
g3 <- graph.bipartite.full (N,N)
#Name the vertices A1...AN and B1..BN
V(g3)$name <- c(paste0("A", 1:N), paste0("B", 1:N))
#set the edge weights
set.seed(122)
E(g3)$weight <- sample(10,N^2, replace=T) #use your fWgt function here instead
#verifty if we did things right
str(g3, TRUE)
is.bipartite(g3)
plot (g3,layout=layout.bipartite,
vertex.color=c("green","cyan")[V(g3)$type+1])
mbm <- maximum.bipartite.matching(g3)
sum(E(g3)$weight)
library(igraph)
N <- 5
g3 <- graph.bipartite.full (N,N)
#Name the vertices A1...AN and B1..BN
V(g3)$name <- c(paste0("A", 1:N), paste0("B", 1:N))
#set the edge weights
set.seed(122)
E(g3)$weight <- sample(10,N^2, replace=T) #use your fWgt function here instead
#verifty if we did things right
str(g3, TRUE)
is.bipartite(g3)
plot (g3,layout=layout.bipartite,
vertex.color=c("green","cyan")[V(g3)$type+1])
mbm <- maximum.bipartite.matching(g3)
sum(E(g3)$weight)
N <- 5
g3 <- graph.bipartite.full (N,N)
#Name the vertices A1...AN and B1..BN
library(igraph)
N <- 5
g3 <- graph.full.bipartite (N,N)
#Name the vertices A1...AN and B1..BN
V(g3)$name <- c(paste0("A", 1:N), paste0("B", 1:N))
#set the edge weights
set.seed(122)
E(g3)$weight <- sample(10,N^2, replace=T) #use your fWgt function here instead
#verifty if we did things right
str(g3, TRUE)
is.bipartite(g3)
plot (g3,layout=layout.bipartite,
vertex.color=c("green","cyan")[V(g3)$type+1])
mbm <- maximum.bipartite.matching(g3)
sum(E(g3)$weight)
library(igraph)
N <- 5
g3 <- graph.full.bipartite (N,N)
#Name the vertices A1...AN and B1..BN
V(g3)$name <- c(paste0("A", 1:N), paste0("B", 1:N))
#set the edge weights
set.seed(122)
E(g3)$weight <- sample(10,N^2, replace=T) #use your fWgt function here instead
#verifty if we did things right
str(g3, TRUE)
is.bipartite(g3)
plot (g3,layout=layout.bipartite,
vertex.color=c("green","cyan")[V(g3)$type+1])
mbm <- maximum.bipartite.matching(g3)
sum(E(g3)$weight)
g <- graph.formula( a-b-c-d-e-f )
m1 <- c("b", "a", "d", "c", "f", "e")   # maximal matching
m2 <- c("b", "a", "d", "c", NA, NA)     # non-maximal matching
m3 <- c("b", "c", "d", "c", NA, NA)     # not a matching
is.matching(g, m1)
is.matching(g, m2)
is.matching(g, m3)
is.maximal.matching(g, m1)
is.maximal.matching(g, m2)
is.maximal.matching(g, m3)
library(igraph)
g <- graph.formula( a-b-c-d-e-f )
m1 <- c("b", "a", "d", "c", "f", "e")   # maximal matching
m2 <- c("b", "a", "d", "c", NA, NA)     # non-maximal matching
m3 <- c("b", "c", "d", "c", NA, NA)     # not a matching
is.matching(g, m2)
V(g)$type <- c(FALSE,TRUE)
str(g, v=TRUE)
maximum.bipartite.matching(g)
str(g, v=TRUE)
maximum.bipartite.matching(g)
addProviderTiles("Stamen.Toner", group = "Toner") %>%
library(leaflet)
#df <- read.csv("PRELIM.csv", header=TRUE)
#df <- read.csv("latlong.csv", header=TRUE)
#df <- na.exclude(df)
#df<-df[-2,]
#head(df$long)
#head(df$lat)
twiticon  <- makeIcon(
iconUrl = "http://leafletjs.com/docs/images/leaf-green.png",
iconWidth = 38, iconHeight = 95,
iconAnchorX = 22, iconAnchorY = 94
)
pal <- colorFactor(c("navy", "red"), domain = c(0, 1))
m <- leaflet()   %>% setView(lng = -1.24757, lat = 50.862676, zoom = 9)%>%
#addTiles() %>%  # Add default OpenStreetMap map tiles  set PO15 5RR as default view
addTiles(group = "OSM (default)") %>%
addProviderTiles("Stamen.Toner", group = "Toner") %>%
addProviderTiles("Stamen.TonerLite", group = "Toner Lite") %>%
addProviderTiles("Stamen.Watercolor", group = "Stamen Watercolor") %>%
addProviderTiles("CartoDB.Positron", group = "CartoDB.Positron") %>%
addProviderTiles("CartoDB.DarkMatter", group = "CartoDB.DarkMatter") %>%
# addMarkers( data = df, lat = ~ lat, lng = ~ long , popup=~username ,icon=twiticon, clusterOptions= markerClusterOptions()) %>%
# Layers control
addLayersControl(
baseGroups = c("OSM (default)", "Toner", "Toner Lite","Stamen Watercolor","CartoDB.Positron", "CartoDB.DarkMatter"),
overlayGroups = c("df", "Outline"),
options = layersControlOptions(collapsed = FALSE)
)
library(leaflet)
install.packages("leaflet")
library(leaflet)
twiticon  <- makeIcon(
iconUrl = "http://leafletjs.com/docs/images/leaf-green.png",
iconWidth = 38, iconHeight = 95,
iconAnchorX = 22, iconAnchorY = 94
)
pal <- colorFactor(c("navy", "red"), domain = c(0, 1))
m <- leaflet()   %>% setView(lng = -1.24757, lat = 50.862676, zoom = 9)%>%
#addTiles() %>%  # Add default OpenStreetMap map tiles  set PO15 5RR as default view
addTiles(group = "OSM (default)") %>%
addProviderTiles("Stamen.Toner", group = "Toner") %>%
addProviderTiles("Stamen.TonerLite", group = "Toner Lite") %>%
addProviderTiles("Stamen.Watercolor", group = "Stamen Watercolor") %>%
addProviderTiles("CartoDB.Positron", group = "CartoDB.Positron") %>%
addProviderTiles("CartoDB.DarkMatter", group = "CartoDB.DarkMatter") %>%
# addMarkers( data = df, lat = ~ lat, lng = ~ long , popup=~username ,icon=twiticon, clusterOptions= markerClusterOptions()) %>%
# Layers control
addLayersControl(
baseGroups = c("OSM (default)", "Toner", "Toner Lite","Stamen Watercolor","CartoDB.Positron", "CartoDB.DarkMatter"),
overlayGroups = c("df", "Outline"),
options = layersControlOptions(collapsed = FALSE)
)
m
lines(predict(xy.lm), y, col='blue')
set.seed(2)
x <- 1:100
y <- 20 + 3 * x
e <- rnorm(100, 0, 60)
y <- 20 + 3 * x + e
plot(x,y)
yx.lm <- lm(y ~ x)
lines(x, predict(yx.lm), col='red')
xy.lm <- lm(x ~ y)
lines(predict(xy.lm), y, col='blue')
xyNorm <- cbind(x=x-mean(x), y=y-mean(y))
plot(xyNorm)
#covariance
xyCov <- cov(xyNorm)
eigenValues <- eigen(xyCov)$values
eigenVectors <- eigen(xyCov)$vectors
plot(xyNorm, ylim=c(-200,200), xlim=c(-200,200))
lines(xyNorm[x], eigenVectors[2,1]/eigenVectors[1,1] * xyNorm[x])
lines(xyNorm[x], eigenVectors[2,2]/eigenVectors[1,2] * xyNorm[x])
View(edgelist)
View(eigenVectors)
plot(xy)
lines(x, (eigenVectors[2,1]/eigenVectors[1,1] * xyNorm[x]) + mean(y))
plot(xy)
lines(x, (eigenVectors[2,1]/eigenVectors[1,1] * xyNorm[x]) + mean(y))
# that looks right. line through the middle as expected
# what if we bring back our other two regressions?
lines(x, predict(yx.lm), col='red')
lines(predict(xy.lm), y, col='blue')
Prior1<-function(n){
mu1<-NULL
mu2<-NULL
lower<-NULL
upper<-NULL
tau<-NULL
for (i in 1:n){
mu1[i]<-runif(1,0,1)
mu2[i]<-runif(1,0,1)
lower[i]<-max(0,(1/mu1[i])+(1/mu2[i])-(1/(mu1[i]*mu2[i])))
upper[i]<-min((1/mu1[i]),(1/mu2[i]))
tau[i]<-runif(1,lower[i],upper[i])
}
return(data.frame(mu1,mu2,tau,lower,upper))
}
Prior1(10)
?igraph_famous
library(igraph)
?igraph_famous
?igraph_ring
library(networkD3)
# load data into a matrix
data <- read.csv(file='Assets-Liabilities.csv', skip=1)
rownames(data) <- data[,1]
data <- as.matrix(data[,-(1:2)])
library(parallel)
no_cores <- detectCores() - 1
no_cores
shiny::runApp('Dropbox/Rcode/LDAShiny')
ecb = function(x,y){ plot(x,t='n'); text(x,labels=iris$Species, col=colors[iris$Species]) }
names(colors) = unique(iris$Species)
ecb = function(x,y){ plot(x,t='n'); text(x,labels=iris$Species, col=colors[iris$Species]) }
tsne_iris = tsne(iris[,1:4], epoch_callback = ecb, perplexity=50)
# compare to PCA
install.packages("tsna")
install.packages("tsne")
library(tsne)
## Not run:
colors = rainbow(length(unique(iris$Species)))
names(colors) = unique(iris$Species)
ecb = function(x,y){ plot(x,t='n'); text(x,labels=iris$Species, col=colors[iris$Species]) }
tsne_iris = tsne(iris[,1:4], epoch_callback = ecb, perplexity=50)
# compare to PCA
dev.new()
pca_iris = princomp(iris[,1:4])$scores[,1:2]
plot(x,t='n')
text(pca_iris, labels=iris$Species,col=colors[iris$Species])
shiny::runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
runApp('Dropbox/Rcode/jobvacs/jobvacancies')
library(plyr)
library(ggplot2)
library(sp)
library(maptools)
#library(threejs)
library(reshape2)
library(rgdal)
library(rgeos)
library(ggmap)
install.packages("rgdal")
library(rgdal)
library(plyr)
library(ggplot2)
library(sp)
library(maptools)
#library(threejs)
library(reshape2)
library(rgdal)
library(rgeos)
library(ggmap)
install.packages("ggmap")
library(plyr)
library(ggplot2)
library(sp)
library(maptools)
#library(threejs)
library(reshape2)
library(rgdal)
install.packages(c('rzmq','repr','IRkernel','IRdisplay'),
repos = c('http://irkernel.github.io/', getOption('repos')))
install.packages(c('rzmq','repr','IRkernel','IRdisplay'),
repos = c('http://irkernel.github.io/', getOption('repos')))
install.packages(c('rzmq'),
repos = c('http://irkernel.github.io/', getOption('repos')))
install.packages(c('IRKernel'),
repos = c('http://irkernel.github.io/', getOption('repos')))
install.packages(c('IRkernel'),
repos = c('http://irkernel.github.io/', getOption('repos')))
install.packages(c(repr','IRkernel','IRdisplay'),
repos = c('http://irkernel.github.io/', getOption('repos')),
type = 'source')
install.packages(c('IRkernel','IRdisplay'),
repos = c('http://irkernel.github.io/', getOption('repos')),
type = 'source')
library(nnet)
library(ggplot2)
library(reshape2)
library(maxent)
library(RTextTools)
#clean up the r environment.
rm(list = ls())
#@home working directory
setwd("/Users/thorosm2002/Dropbox/Rcode/MLinR")
Afile <- 'DEFdry.csv'
rd <- read.csv2(Afile, sep=",", stringsAsFactors=FALSE,header = TRUE)
rd <- rd[,c("ITEMDESC","CCPNODOT")]
keptdata <- rd[!(is.na(rd$ITEMDESC) | rd$ITEMDESC==""), ]
keptdata <- head(keptdata,10000)
testdata <-  tail(keptdata,5000)
dtMatrix <- create_matrix(keptdata, removeSparseTerms = .99999)
# Configure the training data
container <- create_container(dtMatrix, keptdata$CCPNODOT, trainSize=1:5000, testSize = 5001:10000, virgin=FALSE)
svmmodel <- train_model(container,"SVM")
results <- classify_model(container,svmmodel)
total <- cbind(results,testdata)
total$TF <- ifelse(total$CCPNODOT==total$SVM_LABEL,1,0)
hist(total$TF)
View(results)
View(total)
unique(total$ITEMDESC)
unique(rd$ITEMDESC)
?create_matrix
#clean up the r environment.
rm(list = ls())
setwd("/Users/thorosm2002/Dropbox/Rcode/MLinR")
Afile <- 'DEFdry.csv'
rd <- read.csv2(Afile, sep=",", stringsAsFactors=FALSE,header = TRUE)
rd <- rd[,c("ITEMDESC","CCPNODOT")]
keptdata <- rd[!(is.na(rd$ITEMDESC) | rd$ITEMDESC==""), ]
keptdata <- head(keptdata,10000)
testdata <-  tail(keptdata,5000)
dtMatrix <- create_matrix(keptdata, removeStopwords=TRUE,minDocFreq=3,removeSparseTerms = .9999)
# Configure the train
dtMatrix <- create_matrix(keptdata, removeStopwords=TRUE,removeSparseTerms = .9999)
# Configure the training data
container <- create_container(dtMatrix, keptdata$CCPNODOT, trainSize=1:5000, testSize = 5001:10000, virgin=FALSE)
svmmodel <- train_model(container,"SVM")
results <- classify_model(container,svmmodel)
total <- cbind(results,testdata)
total$TF <- ifelse(total$CCPNODOT==total$SVM_LABEL,1,0)
hist(total$TF)
View(total)
dtMatrix <- create_matrix(keptdata, removeNumbers=TRUE, stemWords=TRUE, weighting =tm::weightTfIdf ,removeStopwords=TRUE,removeSparseTerms = .9999)
# Configure the training data
container <- create_container(dtMatrix, keptdata$CCPNODOT, trainSize=1:5000, testSize = 5001:10000, virgin=FALSE)
svmmodel <- train_model(container,"SVM")
results <- classify_model(container,svmmodel)
total <- cbind(results,testdata)
total$TF <- ifelse(total$CCPNODOT==total$SVM_LABEL,1,0)
hist(total$TF)
